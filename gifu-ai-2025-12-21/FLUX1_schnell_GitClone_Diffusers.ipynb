{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPqvxr1FBIEOiouxsR3o/7N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fukagai-takuya/gifu-ai/blob/main/gifu-ai-2025-12-21/FLUX1_schnell_GitClone_Diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Google Drive のマウント (Google Drive 側で予め下記のコマンドを実行していると仮定しています。)\n",
        "\n",
        "git clone https://github.com/huggingface/diffusers.git"
      ],
      "metadata": {
        "id": "Z-AjEHT1qsE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "y9AJFW3Ejn0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. git clone した diffusers のソースコードを優先して参照するようにします"
      ],
      "metadata": {
        "id": "PnRY7dtcreT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/drive/MyDrive/diffusers/src\")"
      ],
      "metadata": {
        "id": "S_7AeBUgr1p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. git clone した diffusers のソースコードが優先して参照されることを確認します"
      ],
      "metadata": {
        "id": "i16Yd6gQrrVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import diffusers\n",
        "print(diffusers.__file__)"
      ],
      "metadata": {
        "id": "30HLguOisLZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. diffusers を使用して FLUX.1 [schnell] を実行する際に必要なパッケージをインストールします"
      ],
      "metadata": {
        "id": "VvpWVDjHTFLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install transformers accelerate safetensors\n",
        "!pip install sentencepiece protobuf einops"
      ],
      "metadata": {
        "id": "LMVmmF1lrcnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. pdb より高機能な Python デバッガ ipdb をインストールします"
      ],
      "metadata": {
        "id": "E2_s9KktTX3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipdb"
      ],
      "metadata": {
        "id": "Q2DpDWm_u4td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. FLUX.1 [schnell] を使用した Pipeline を用意します"
      ],
      "metadata": {
        "id": "6rcr1kI4TWnE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Npt43B6bjRnL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import FluxPipeline\n",
        "\n",
        "pipe = FluxPipeline.from_pretrained(\n",
        "    \"black-forest-labs/FLUX.1-schnell\",\n",
        "    torch_dtype=torch.float16\n",
        ").to(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    guidance_scale=0.0,\n",
        "    num_inference_steps=4,\n",
        "    max_sequence_length=256,\n",
        "    generator=torch.Generator(\"cpu\").manual_seed(0)\n",
        ").images[0]\n",
        "\n",
        "image.save(\"Gifu-AI-study-group.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "6gQ3hKZ-APin",
        "outputId": "3c0e510f-84da-4ca1-dd97-6639d8fde0d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pipe' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2943401060.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Clean white background, vibrant and diverse colors, sharp details, balanced composition.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m image = pipe(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mguidance_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "out_dir = \"steps\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# GIF 用に画像を溜めるリスト\n",
        "gif_frames = []\n",
        "\n",
        "def callback(step: int, timestep: int, latents: torch.FloatTensor):\n",
        "    with torch.no_grad():\n",
        "        image = pipe.vae.decode(\n",
        "            latents / pipe.vae.config.scaling_factor\n",
        "        ).sample\n",
        "\n",
        "        image = (image / 2 + 0.5).clamp(0, 1)\n",
        "        image = image.cpu().permute(0, 2, 3, 1).numpy()\n",
        "\n",
        "        img = Image.fromarray((image[0] * 255).astype(\"uint8\"))\n",
        "\n",
        "        # 各 step の PNG 保存（任意）\n",
        "        img.save(os.path.join(out_dir, f\"step_{step:03d}.png\"))\n",
        "\n",
        "        # GIF 用に追加\n",
        "        gif_frames.append(img)\n",
        "\n",
        "pipe(\n",
        "    prompt=\"a futuristic city at sunset\",\n",
        "    num_inference_steps=8,   # schnell\n",
        "    callback=callback,\n",
        "    callback_steps=1\n",
        ")\n",
        "\n",
        "# ===== 推論後に GIF を作成 =====\n",
        "gif_path = \"denoising.gif\"\n",
        "\n",
        "gif_frames[0].save(\n",
        "    gif_path,\n",
        "    save_all=True,\n",
        "    append_images=gif_frames[1:],\n",
        "    duration=200,  # ms / frame\n",
        "    loop=0\n",
        ")\n",
        "\n",
        "print(f\"GIF saved to {gif_path}\")\n"
      ],
      "metadata": {
        "id": "iuQ8mbBIPSqY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}